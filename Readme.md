**2020 년 목표**

+ ***02월 - #1 프로젝트 릴리즈***
+ ***06월 - #2 프로젝트 릴리즈***
+ ***10월 - #3 프로젝트 릴리즈***
+ ***12월 - #4 프로젝트 릴리즈***

## ***Front-end***

GraphQL, RxJS, next, ssr, jest / unit, typescript, electron

Vue.js, Angluar.js, Svelte.js

## ***Back-end***

Docker, nginX

## ***Database***

PostgreSQL, MongoDB, MS-SQL

## ***Language***

### **Python**

**Python 배우기**, 우선 pip이나 venv같은것 먼저 보기

+ [신남님 추천](http://pythonstudy.xyz/python/article/6-Python-%EC%BD%94%EB%94%A9%EC%9D%98-%EA%B8%B0%EC%B4%88](http://pythonstudy.xyz/python/article/6-Python-코딩의-기초))

+ T 아카데미의 [Python 프로그래밍](https://tacademy.sktechx.com/live/player/onlineLectureDetail.action?seq=89): 파이썬 3 기반 기초 
+ T 아카데미의 [Python을 활용한 데이터분석 기초](https://tacademy.sktechx.com/live/player/onlineLectureDetail.action?seq=132): Jupyter Notebook기반으로 Pandas, Seaborn 실습
+  [T 아카데미의 Python을 이용한 데이터분석 실습](https://tacademy.sktechx.com/live/player/onlineLectureDetail.action?seq=119)
+ Edwith의 [머신러닝을 위한 Python](https://www.edwith.org/aipython/joinLectures/14365)

**Tensorflow 배우기 **

+ [Tensorflow 공식 홈페이지](https://www.tensorflow.org/tutorials/)
+ [골빈해커의 텐서플로우 강좌](https://github.com/golbin/TensorFlow-Tutorials)
+ [이찬우님의 텐서플로우 유튜브 강좌](https://www.youtube.com/watch?v=a74pFg8paVc&list=PL1H8jIvbSo1qlXVcdZTH2xsYFp3e1Nmjf)
+ [Tensorflow로 MNIST 실습 SlideShare](https://www.slideshare.net/leeseungeun/tensorflow-tutorial-72217416)

**CNN 이해**

+  [초보자가 이해하기 좋은 CNN 이해 SlideShare](https://www.slideshare.net/leeseungeun/cnn-vgg-72164295)
+ [CNN 스탠포드 강좌 - CS231n](http://- 초보자가 이해하기 좋은 CNN, RNN 이해 SlideShare)

**RNN 이해**

+  [초보자가 이해하기 좋은 CNN, RNN 이해 SlideShare](https://www.slideshare.net/modulabs/2-cnn-rnn)
+ [RNN LSTM 이해 - Colah](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)



## Ai (Machine Learning & Deep Learning)

+ 퍼셉트론
+ 신경망

- [선형 대수학 – 칸 아카데미](https://www.khanacademy.org/math/linear-algebra)
- [미적분학 – Thinkwell](https://www.youtube.com/watch?v=EX_is9LzFSY)
- [미적분학 – 칸 아카데미](https://www.khanacademy.org/math/differential-calculus)
- [통계 학습 입문 ](http://www-bcf.usc.edu/~gareth/ISL)
- [최적화 방법 (Lagrange multipliers) – 칸 아카데미](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-examples)
- [완벽한 파이썬 부트 캠프 – Jose Portilla, Udemy](https://www.udemy.com/complete-python-bootcamp)
- [데이터 과학 및 머신러닝(ML)을 위한 Python – Jose Portilla, Udemy](https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp)
- [머신러닝(ML) – Andrew Ng, Stanford, Coursera](https://www.coursera.org/learn/machine-learning)
- [머신러닝(ML)을 위한 신경망 – Geoffrey Hinton, 토론토 대학, Coursera](https://www.coursera.org/learn/neural-networks)



[Edwith의 인공지능, 딥러닝 강좌](https://www.edwith.org/)

  \- [조경현 교수님의 딥러닝을 이용한 자연어 처리](https://www.edwith.org/deepnlp/lecture/29197/)

+ Supervised Learning: Hypothesis  set <-> DAG (비순환 그래프)를 만드는 과정
+ Disttribution: Binary classification (이진분류), Multicase classification (다중 분류), Linear regression (선형 회귀), Multimodal linear regression (다항 회귀)



[T 아카데미의 인공지능](https://tacademy.sktechx.com/live/player/listOnline.action)[ 강좌](https://tacademy.sktechx.com/live/player/listOnline.action)

   \- [인공지능을 위한 머신러닝 알고리즘](https://tacademy.sktechx.com/live/player/onlineLectureDetail.action?seq=103)

+ 김성훈 & 앤드류응 교수님의 강좌수강 후 개념 정리용 (단, 수학공식이 많이 나옴, [수학방](http://mathbang.net/)을 이용하자)
+ 설명중 [회귀 모델에 대한 보다 자세한 설명](https://brunch.co.kr/@gimmesilver/17)
+ 설명중 [우도(가능도-Likelihood) 자세한 설명](http://rstudio-pubs-static.s3.amazonaws.com/204928_c2d6c62565b74a4987e935f756badfba.html)



[Microsoft의 데이터 과학 전문 프로그램](https://academy.microsoft.com/en-us/professional-program/tracks/data-science/)

+ 필수 과목 11개
+ 과정당 12시간: 하루 2시간 계산하면 과정당 1주가 걸림 -> 총 11주 프로그램     
+ 필요한 것을 선별해서 보면 좋을 듯함.



**용어 이해**

 \- [Softmax 이해](http://mongxmongx2.tistory.com/30?category=654373)

 \- [Activation Function 이해](http://mongxmongx2.tistory.com/13?category=654373)

 \- [Back Propagation 이해](http://llnntms.tistory.com/31). [수식으로 설명](http://aikorea.org/cs231n/optimization-2/), [코드로 설명](https://www.slideshare.net/freepsw/backpropagationcs231n)

 \- [ReLu 이해](http://mongxmongx2.tistory.com/13?category=654373): 역전파의 오류 방지

 \- [알고리즘 복잡도 이해](http://gompangs.tistory.com/31) - Big O == "[최악의 경우(시간복잡도가 클 경우)에도 이 시간 정도면 된다](http://baekhorang.tistory.com/entry/전산학개론04-알고리즘Algorithm-개념-및-용어정리)" 라는 의미

 \- [Log 함수 이해](https://ko.wikipedia.org/wiki/로그)

 \- [tanh 이해](https://ko.wikipedia.org/wiki/쌍곡선함수)

 \- [LSTM 이해](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)



**<참조>**

\- [인공지능과 머신러닝 학습 경로](https://projectresearch.co.kr/2017/06/14/인공지능ai과-머신러닝ml-학습-경로/)

\- [테리님 블로그](http://t-robotics.blogspot.com/2015/05/deep-learning.html#.W2OxvtgzYWp)

\- [조대협님 블로그](http://bcho.tistory.com/1140?category=555440)

\- [조경현 교수님의 뉴욕댁 머신러닝 강좌 소개](https://sites.google.com/site/deepernn/home/blog/lecturenotebriefintroductiontomachinelearningwithoutdeeplearning) 및 [소스](https://github.com/nyu-dl/Intro_to_ML_Lecture_Note)

\- 조경현 교수님이 참조하였다는 [머신러닝의 강의 자료](http://people.csail.mit.edu/dsontag/courses/ml16/)

\- [시그모이드 함수 설명
](http://bcho.tistory.com/1142)

[-](http://bcho.tistory.com/1142) [Activation Function 설명](http://prog3.com/sbdm/blog/cyh_24/article/details/50593400)

[-](http://bcho.tistory.com/1142) [역전파(Backpropagation) 설명](http://jaejunyoo.blogspot.com/2017/01/backpropagation.html), [잘 이해해야 함 (Adnrej Karpathy)](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b), [Andrej의 RNN 이야기](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)

\- [로그함수 설명](https://ghebook.blogspot.com/2011/02/logarithmic-function.html)

\- [수학방](http://mathbang.net/)의 [로그함수 좀더 기초적 설명](http://mathbang.net/595)

\- [수학 기호 명칭](https://librewiki.net/wiki/수학_기호) - 수식을 볼려면 기호의 의미를 알아야 한다.

\- [미분에 대한 쉬운 이해](https://ko.wikiversity.org/wiki/미적분에_대한_쉬운_이해)

\- [MNIST - yann.lecun.com](http://yann.lecun.com/exdb/mnist/)



## etc

- 자바스크립트 책 쓰기